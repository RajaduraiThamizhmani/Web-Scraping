{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAA0o_U1adwq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from selenium import webdriver\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "#To configure webdriver to use Chrome browser, we have to set the path to chromedriver\n",
        "driver = webdriver.Chrome(\"E:\\DATA SCIENCE\\Python/chromedriver\")\n",
        "#driver = webdriver.Chrome(\"D:\\Python workspace\\WebScraping\\venv\\Lib\\site-packages\\chromedriver\")\n",
        "#driver = webdriver.Chrome(executable_path=os.path.abspath(\"chromedriver.exe\")\n",
        "\n",
        "#Refer the below code to open the URL:\n",
        "products = [] #List to store name of the product\n",
        "prices = []   #List to store price of the product\n",
        "ratings = []  #List to store rating of the product\n",
        "\n",
        "driver.get(\"https://www.flipkart.com/laptops/~buyback-guarantee-on-laptops-/pr?sid=6bo%2Cb5g&uniq\")\n",
        "\n",
        "\"\"\"\n",
        "Now that we have written the code to open the URL, itâ€™s time to extract the data from the website. \n",
        "As mentioned earlier, the data we want to extract is nested in <div> tags. \n",
        "So, I will find the div tags with those respective class-names, extract the data and store the data in a variable.\n",
        "Refer the code below:\n",
        "\"\"\"\n",
        "\n",
        "content = driver.page_source\n",
        "soup = BeautifulSoup(content,features=\"html.parser\")\n",
        "\n",
        "for a in soup.findAll('a',href=True, attrs={'class':'_31qSD5'}):\n",
        "    name=a.find('div', attrs={'class': '_3wU53n'})\n",
        "    price=a.find('div', attrs={'class':'_1vC4OE _2rQ-NK'})\n",
        "    rating=a.find('div', attrs={'class':\"hGSR34\"})\n",
        "    products.append(name.text)\n",
        "    prices.append(price.text)\n",
        "    ratings.append(rating.text)\n",
        "\n",
        "df = pd.DataFrame({'Product Name':products,'Price':prices,'Rating':ratings})\n",
        "df.to_csv('products1.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RRfqHkQadw6"
      },
      "outputs": [],
      "source": [
        "name.text\n",
        "price.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_-v1MfZadw7",
        "outputId": "0d279b95-68f6-4901-8f17-3f769ae038c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.3'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating.text"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}